{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"import os\n%matplotlib inline\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.multiclass import OneVsRestClassifier","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:07:23.987992Z","iopub.execute_input":"2022-04-15T14:07:23.988468Z","iopub.status.idle":"2022-04-15T14:07:25.930055Z","shell.execute_reply.started":"2022-04-15T14:07:23.988331Z","shell.execute_reply":"2022-04-15T14:07:25.929000Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data_dir = \"../input/plant-seedlings-classification/\"\ntrain_dir = os.path.join(data_dir, \"train\")\ntest_dir = os.path.join(data_dir, \"test\")","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:07:25.931876Z","iopub.execute_input":"2022-04-15T14:07:25.932177Z","iopub.status.idle":"2022-04-15T14:07:25.937532Z","shell.execute_reply.started":"2022-04-15T14:07:25.932132Z","shell.execute_reply":"2022-04-15T14:07:25.936368Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/gaborvecsei/plant-seedlings-fun-with-computer-vision/notebook\n\nimages_per_class = {}\n\nfor class_folder_name in os.listdir(train_dir):\n    class_folder_path = os.path.join(train_dir, class_folder_name)\n    class_label = class_folder_name\n    images_per_class[class_label] = []\n    \n    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n        image_bgr = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        images_per_class[class_label].append(image_bgr)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:08:01.527128Z","iopub.execute_input":"2022-04-15T14:08:01.527450Z","iopub.status.idle":"2022-04-15T14:09:13.987727Z","shell.execute_reply.started":"2022-04-15T14:08:01.527419Z","shell.execute_reply":"2022-04-15T14:09:13.986660Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Image Segmentation: Pre-Processing Functions","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/gaborvecsei/plant-seedlings-fun-with-computer-vision/notebook\n\nimport cv2\nimport numpy as np\n\ndef create_mask_for_plant(image):\n    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n    sensitivity = 35\n    lower_hsv = np.array([60 - sensitivity, 100, 50])\n    upper_hsv = np.array([60 + sensitivity, 255, 255])\n\n    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    \n    return mask\n\ndef segment_plant(image):\n    mask = create_mask_for_plant(image)\n    output = cv2.bitwise_and(image, image, mask = mask)\n    return output\n\ndef sharpen_image(image):\n    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n    return image_sharp","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:09:13.990022Z","iopub.execute_input":"2022-04-15T14:09:13.990377Z","iopub.status.idle":"2022-04-15T14:09:14.001246Z","shell.execute_reply.started":"2022-04-15T14:09:13.990330Z","shell.execute_reply":"2022-04-15T14:09:14.000205Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Test image to see the changes\n\n# https://www.kaggle.com/gaborvecsei/plant-seedlings-fun-with-computer-vision/notebook\nimage = images_per_class[\"Cleavers\"][0]\n\nimage_mask = create_mask_for_plant(image)\nimage_segmented = segment_plant(image)\nimage_sharpen = sharpen_image(image_segmented)\n\nfig, axs = plt.subplots(1, 4, figsize=(20, 20))\naxs[0].imshow(image)\naxs[1].imshow(image_mask)\naxs[2].imshow(image_segmented)\naxs[3].imshow(image_sharpen)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:09:14.002623Z","iopub.execute_input":"2022-04-15T14:09:14.002970Z","iopub.status.idle":"2022-04-15T14:09:14.856850Z","shell.execute_reply.started":"2022-04-15T14:09:14.002923Z","shell.execute_reply":"2022-04-15T14:09:14.855620Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Load Images and Labels","metadata":{}},{"cell_type":"markdown","source":"### 1. Gray scaling, segmentation (and sharpening)","metadata":{}},{"cell_type":"code","source":"images_gray, labels_gray = [], []\n\nfor class_folder_name in os.listdir(train_dir):\n    class_folder_path = os.path.join(train_dir, class_folder_name)\n    \n    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image_150 = cv2.resize(image, (299, 299))\n        image_segmented = segment_plant(image_150)\n        image_sharpened = sharpen_image(image_segmented)\n        image_gray = cv2.cvtColor(image_sharpened, cv2.COLOR_BGR2GRAY)\n        image_45 = cv2.resize(image_gray, (299,299))\n        image_flat = image_45.flatten()\n        images_gray.append(image_flat)\n        labels_gray.append(class_folder_name)\n\nimages_gray = np.array(images_gray)\nlabels_gray = np.array(labels_gray)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:07:55.751929Z","iopub.status.idle":"2022-04-15T14:07:55.752467Z","shell.execute_reply.started":"2022-04-15T14:07:55.752167Z","shell.execute_reply":"2022-04-15T14:07:55.752198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(labels_gray)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:07:55.755141Z","iopub.status.idle":"2022-04-15T14:07:55.756173Z","shell.execute_reply.started":"2022-04-15T14:07:55.755811Z","shell.execute_reply":"2022-04-15T14:07:55.755849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_test_gray = []\n\nfor image_path in glob(os.path.join(test_dir, \"*.png\")):\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    image_150 = cv2.resize(image, (299, 299))\n    image_segmented = segment_plant(image_150)\n    image_sharpened = sharpen_image(image_segmented)\n    image_gray = cv2.cvtColor(image_sharpened, cv2.COLOR_BGR2GRAY)\n    image_45 = cv2.resize(image_gray, (299,299))\n    image_flat = image_45.flatten()\n    images_test_gray.append(image_flat)  \n\nimages_test_gray = np.array(images_test_gray)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:07:55.757585Z","iopub.status.idle":"2022-04-15T14:07:55.758265Z","shell.execute_reply.started":"2022-04-15T14:07:55.757952Z","shell.execute_reply":"2022-04-15T14:07:55.757984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Segmentation (and sharpening)","metadata":{}},{"cell_type":"code","source":"images, labels = [], []\n\nfor class_folder_name in os.listdir(train_dir):\n    class_folder_path = os.path.join(train_dir, class_folder_name)\n    \n    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image_150 = cv2.resize(image, (299, 299))\n        image_segmented = segment_plant(image_150)\n        image_sharpened = sharpen_image(image_segmented)\n        image_45 = cv2.resize(image_sharpened, (299,299))\n        image_flat = image_45.flatten()\n        images.append(image_flat)\n        labels.append(class_folder_name)\n\nimages = np.array(images)\nlabels = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:09:14.859698Z","iopub.execute_input":"2022-04-15T14:09:14.860053Z","iopub.status.idle":"2022-04-15T14:10:22.775576Z","shell.execute_reply.started":"2022-04-15T14:09:14.860007Z","shell.execute_reply":"2022-04-15T14:10:22.774569Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"np.unique(labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:10:22.777286Z","iopub.execute_input":"2022-04-15T14:10:22.777698Z","iopub.status.idle":"2022-04-15T14:10:22.786080Z","shell.execute_reply.started":"2022-04-15T14:10:22.777649Z","shell.execute_reply":"2022-04-15T14:10:22.785087Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"images_test = []\n\nfor image_path in glob(os.path.join(test_dir, \"*.png\")):\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    image_150 = cv2.resize(image, (299, 299))\n    image_segmented = segment_plant(image_150)\n    image_sharpened = sharpen_image(image_segmented)\n    image_45 = cv2.resize(image_sharpened, (299,299))\n    image_flat = image_45.flatten()\n    images_test.append(image_flat)  \n\nimages_test = np.array(images_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:10:22.787713Z","iopub.execute_input":"2022-04-15T14:10:22.788074Z","iopub.status.idle":"2022-04-15T14:10:34.479508Z","shell.execute_reply.started":"2022-04-15T14:10:22.788016Z","shell.execute_reply":"2022-04-15T14:10:34.478449Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### 3. No pre-processing","metadata":{}},{"cell_type":"code","source":"images_basic, labels_basic = [], []\n\nfor class_folder_name in os.listdir(train_dir):\n    class_folder_path = os.path.join(train_dir, class_folder_name)\n    \n    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image_45 = cv2.resize(image, (299,299))\n        image_flat = image_45.flatten()\n        images_basic.append(image_flat)\n        labels_basic.append(class_folder_name)\n\nimages_basic = np.array(images_basic)\nlabels_basic = np.array(labels_basic)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:16:22.077021Z","iopub.execute_input":"2022-04-15T12:16:22.077216Z","iopub.status.idle":"2022-04-15T12:17:12.384845Z","shell.execute_reply.started":"2022-04-15T12:16:22.077191Z","shell.execute_reply":"2022-04-15T12:17:12.383920Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"np.unique(labels_basic)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:17:12.386150Z","iopub.execute_input":"2022-04-15T12:17:12.386382Z","iopub.status.idle":"2022-04-15T12:17:12.393452Z","shell.execute_reply.started":"2022-04-15T12:17:12.386353Z","shell.execute_reply":"2022-04-15T12:17:12.392468Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"images_test_basic = []\n\nfor image_path in glob(os.path.join(test_dir, \"*.png\")):\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    image_45 = cv2.resize(image, (299,299))\n    image_flat = image_45.flatten()\n    images_test_basic.append(image_flat)  \n\nimages_test_basic = np.array(images_test_basic)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:29:13.823246Z","iopub.execute_input":"2022-04-15T12:29:13.823791Z","iopub.status.idle":"2022-04-15T12:29:17.077002Z","shell.execute_reply.started":"2022-04-15T12:29:13.823751Z","shell.execute_reply":"2022-04-15T12:29:17.076078Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"## Label Pre-Processing","metadata":{}},{"cell_type":"code","source":"# convert the text labels to numerical ones for prediction scores\ntext_label_to_num_label_dict = {v:i for i,v in enumerate(np.unique(labels))}\ntext_label_to_num_label_dict","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:10:34.480957Z","iopub.execute_input":"2022-04-15T14:10:34.481263Z","iopub.status.idle":"2022-04-15T14:10:34.490971Z","shell.execute_reply.started":"2022-04-15T14:10:34.481221Z","shell.execute_reply":"2022-04-15T14:10:34.489683Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# convert numerical ids to text labels\nnum_label_to_text_label_dict = {v: k for k, v in text_label_to_num_label_dict.items()}\nnum_label_to_text_label_dict","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:10:34.492267Z","iopub.execute_input":"2022-04-15T14:10:34.492726Z","iopub.status.idle":"2022-04-15T14:10:34.501852Z","shell.execute_reply.started":"2022-04-15T14:10:34.492687Z","shell.execute_reply":"2022-04-15T14:10:34.500967Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"truth_labels_gray = np.array([text_label_to_num_label_dict[x] for x in labels_gray])\ntruth_labels_gray","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:07:55.762585Z","iopub.status.idle":"2022-04-15T14:07:55.762969Z","shell.execute_reply.started":"2022-04-15T14:07:55.762797Z","shell.execute_reply":"2022-04-15T14:07:55.762815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"truth_labels = np.array([text_label_to_num_label_dict[x] for x in labels])\ntruth_labels","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:10:34.503083Z","iopub.execute_input":"2022-04-15T14:10:34.503518Z","iopub.status.idle":"2022-04-15T14:10:34.518933Z","shell.execute_reply.started":"2022-04-15T14:10:34.503476Z","shell.execute_reply":"2022-04-15T14:10:34.517722Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"truth_labels_basic = np.array([text_label_to_num_label_dict[x] for x in labels_basic])\ntruth_labels_basic","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:17:12.463890Z","iopub.execute_input":"2022-04-15T12:17:12.464317Z","iopub.status.idle":"2022-04-15T12:17:12.477312Z","shell.execute_reply.started":"2022-04-15T12:17:12.464255Z","shell.execute_reply":"2022-04-15T12:17:12.476563Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"if (truth_labels_gray == truth_labels).all() and (truth_labels_basic == truth_labels).all():\n    print(\"Same!\")","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:17:12.478620Z","iopub.execute_input":"2022-04-15T12:17:12.478838Z","iopub.status.idle":"2022-04-15T12:17:12.490274Z","shell.execute_reply.started":"2022-04-15T12:17:12.478811Z","shell.execute_reply":"2022-04-15T12:17:12.489421Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## PCA\n##### Code reference: \nhttps://www.kaggle.com/code/tomras/sentiment-analysis-of-tweets-using-pca-and-ml/notebook","metadata":{}},{"cell_type":"markdown","source":"### 1. Segmented Images (with sharpening)","metadata":{}},{"cell_type":"code","source":"# # image size: 45, 45, 3\n# image_data = images.flatten().reshape(4750, 6075)\n\n# # 2 principle components\n# pca = PCA(n_components = 2)\n# pca_data = pca.fit_transform(image_data)\n\n# pca_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:04:38.772651Z","iopub.execute_input":"2022-04-15T14:04:38.773000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_pca_data = pd.DataFrame(pca_data)\n# df_labels = pd.DataFrame(truth_labels)\n# df_pca_data = pd.concat([df_pca_data, df_labels], axis=1, ignore_index=True)\n# df_pca_data.columns = ['pca_1', 'pca_2', 'target']\n# df_pca_data.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:41:43.094253Z","iopub.execute_input":"2022-04-15T13:41:43.094549Z","iopub.status.idle":"2022-04-15T13:41:43.119009Z","shell.execute_reply.started":"2022-04-15T13:41:43.094520Z","shell.execute_reply":"2022-04-15T13:41:43.118165Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"# df_text_labels = pd.DataFrame(labels)\n# df_pca_data = pd.concat([df_pca_data, df_text_labels], axis=1, ignore_index=True)\n# df_pca_data.columns = ['pca_1', 'pca_2', 'target','text']","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:41:44.279616Z","iopub.execute_input":"2022-04-15T13:41:44.280066Z","iopub.status.idle":"2022-04-15T13:41:44.286469Z","shell.execute_reply.started":"2022-04-15T13:41:44.280035Z","shell.execute_reply":"2022-04-15T13:41:44.285685Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(16,10))\n# sns.scatterplot(\n#     x=\"pca_1\", y=\"pca_2\",\n#     hue=\"text\",\n#     data=df_pca_data,\n#     legend=\"full\",\n#     palette='colorblind'\n# )","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:41:47.762541Z","iopub.execute_input":"2022-04-15T13:41:47.763270Z","iopub.status.idle":"2022-04-15T13:41:48.952177Z","shell.execute_reply.started":"2022-04-15T13:41:47.763223Z","shell.execute_reply":"2022-04-15T13:41:48.951466Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":"### 2. No pre-processing","metadata":{}},{"cell_type":"code","source":"# # image size: 45, 45, 3\n# image_data = images_basic.flatten().reshape(4750, 6075)\n\n# # 2 principle components\n# pca = PCA(n_components = 2)\n# pca_data = pca.fit_transform(image_data)\n\n# pca_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_pca_data = pd.DataFrame(pca_data)\n# df_labels = pd.DataFrame(truth_labels)\n# df_pca_data = pd.concat([df_pca_data, df_labels], axis=1, ignore_index=True)\n# df_pca_data.columns = ['pca_1', 'pca_2', 'target']\n# df_pca_data.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:42:01.064037Z","iopub.execute_input":"2022-04-15T13:42:01.064325Z","iopub.status.idle":"2022-04-15T13:42:01.090148Z","shell.execute_reply.started":"2022-04-15T13:42:01.064293Z","shell.execute_reply":"2022-04-15T13:42:01.089256Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"# df_text_labels = pd.DataFrame(labels)\n# df_pca_data = pd.concat([df_pca_data, df_text_labels], axis=1, ignore_index=True)\n# df_pca_data.columns = ['pca_1', 'pca_2', 'target','text']","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:42:04.997749Z","iopub.execute_input":"2022-04-15T13:42:04.998033Z","iopub.status.idle":"2022-04-15T13:42:05.005806Z","shell.execute_reply.started":"2022-04-15T13:42:04.998004Z","shell.execute_reply":"2022-04-15T13:42:05.004594Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(16,10))\n# sns.scatterplot(\n#     x=\"pca_1\", y=\"pca_2\",\n#     hue=\"text\",\n#     data=df_pca_data,\n#     legend=\"full\",\n#     palette='colorblind'\n# )","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:42:06.064153Z","iopub.execute_input":"2022-04-15T13:42:06.064470Z","iopub.status.idle":"2022-04-15T13:42:06.966080Z","shell.execute_reply.started":"2022-04-15T13:42:06.064432Z","shell.execute_reply":"2022-04-15T13:42:06.965177Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"markdown","source":"## K-Means\n\n##### Sources: \nhttps://medium.com/@joel_34096/k-means-clustering-for-image-classification-a648f28bdc47\n\nhttps://www.analyticsvidhya.com/blog/2021/06/k-means-clustering-and-transfer-learning-for-image-classification/","metadata":{}},{"cell_type":"code","source":"# source: https://medium.com/@joel_34096/k-means-clustering-for-image-classification-a648f28bdc47\n\ndef retrieve_info(cluster_labels,y_train):\n    \"\"\"\n    Associates most probable label with each cluster in KMeans model\n    returns: dictionary of clusters assigned to each label\n    \"\"\"\n    # Initializing\n    reference_labels = {}\n    # For loop to run through each label of cluster label\n    for i in range(len(np.unique(cluster_labels))):\n        index = np.where(cluster_labels == i,1,0)\n        num = np.bincount(y_train[index==1]).argmax()\n        reference_labels[i] = num\n    return reference_labels","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:10:34.523281Z","iopub.execute_input":"2022-04-15T14:10:34.524029Z","iopub.status.idle":"2022-04-15T14:10:34.532098Z","shell.execute_reply.started":"2022-04-15T14:10:34.523981Z","shell.execute_reply":"2022-04-15T14:10:34.531045Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# initializing k means with 12 clusters (we have 12 classes)\ndef kmeans(input_labels, input_images):\n    model_kmeans = KMeans(n_clusters = len(np.unique(input_labels)), init='random')\n    model_kmeans.fit(input_images)\n    return model_kmeans","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:10:34.533384Z","iopub.execute_input":"2022-04-15T14:10:34.533724Z","iopub.status.idle":"2022-04-15T14:10:34.545419Z","shell.execute_reply.started":"2022-04-15T14:10:34.533693Z","shell.execute_reply":"2022-04-15T14:10:34.544525Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def map_kmeans_to_actual_labels(input_labels, reference_labels):\n    pred_labels = []\n    for i in range(len(input_labels)):\n        k_means_label = input_labels[i]\n        ref_label_mapping = reference_labels[k_means_label]\n        pred_labels.append(ref_label_mapping)\n    return pred_labels","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:10:34.546534Z","iopub.execute_input":"2022-04-15T14:10:34.547122Z","iopub.status.idle":"2022-04-15T14:10:34.557134Z","shell.execute_reply.started":"2022-04-15T14:10:34.547084Z","shell.execute_reply":"2022-04-15T14:10:34.556439Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### 1. Gray scaling + segmentation (with sharpening)","metadata":{}},{"cell_type":"code","source":"# initialize kmeans and fit on images\nmodel_kmeans_gray = kmeans(labels_gray, images_gray)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:17:12.531601Z","iopub.execute_input":"2022-04-15T12:17:12.532086Z","iopub.status.idle":"2022-04-15T12:17:36.852329Z","shell.execute_reply.started":"2022-04-15T12:17:12.532052Z","shell.execute_reply":"2022-04-15T12:17:36.851670Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"np.unique(model_kmeans_gray.labels_)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:17:36.853279Z","iopub.execute_input":"2022-04-15T12:17:36.853527Z","iopub.status.idle":"2022-04-15T12:17:36.859974Z","shell.execute_reply.started":"2022-04-15T12:17:36.853497Z","shell.execute_reply":"2022-04-15T12:17:36.859278Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# find mapping for k means labels according to truth_labels\nreference_labels_dict = retrieve_info(model_kmeans_gray.labels_ , truth_labels)\nreference_labels_dict","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:18:55.342370Z","iopub.execute_input":"2022-04-15T12:18:55.342854Z","iopub.status.idle":"2022-04-15T12:18:55.350250Z","shell.execute_reply.started":"2022-04-15T12:18:55.342823Z","shell.execute_reply":"2022-04-15T12:18:55.349496Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# map the k means labels to the actual labels using reference_labels_dict\npred_labels = map_kmeans_to_actual_labels(model_kmeans_gray.labels_, reference_labels_dict)\n# calc accuracy\naccuracy_score(pred_labels ,truth_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:18:57.527148Z","iopub.execute_input":"2022-04-15T12:18:57.527464Z","iopub.status.idle":"2022-04-15T12:18:57.551180Z","shell.execute_reply.started":"2022-04-15T12:18:57.527428Z","shell.execute_reply":"2022-04-15T12:18:57.550403Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### 2. Segmentation (with sharpening)","metadata":{}},{"cell_type":"code","source":"# initialize kmeans and fit on images\nmodel_kmeans_seg = kmeans(labels, images)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T14:10:34.558210Z","iopub.execute_input":"2022-04-15T14:10:34.558686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(model_kmeans_seg.labels_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find mapping for k means labels according to truth_labels\nreference_labels_dict = retrieve_info(model_kmeans_seg.labels_ , truth_labels)\nreference_labels_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# map the k means labels to the actual labels using reference_labels_dict\npred_labels = map_kmeans_to_actual_labels(model_kmeans_seg.labels_, reference_labels_dict)\n# calc accuracy\naccuracy_score(pred_labels ,truth_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. No pre-processing","metadata":{}},{"cell_type":"code","source":"# initialize kmeans and fit on images\nmodel_kmeans_basic = kmeans(labels_basic, images_basic)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:19:38.076446Z","iopub.execute_input":"2022-04-15T12:19:38.078292Z","iopub.status.idle":"2022-04-15T12:20:21.314208Z","shell.execute_reply.started":"2022-04-15T12:19:38.078251Z","shell.execute_reply":"2022-04-15T12:20:21.313457Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"np.unique(model_kmeans_basic.labels_)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:20:21.315284Z","iopub.execute_input":"2022-04-15T12:20:21.315682Z","iopub.status.idle":"2022-04-15T12:20:21.322041Z","shell.execute_reply.started":"2022-04-15T12:20:21.315650Z","shell.execute_reply":"2022-04-15T12:20:21.321424Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# find mapping for k means labels according to truth_labels\nreference_labels_dict = retrieve_info(model_kmeans_basic.labels_ , truth_labels)\nreference_labels_dict","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:20:21.323235Z","iopub.execute_input":"2022-04-15T12:20:21.323540Z","iopub.status.idle":"2022-04-15T12:20:21.338723Z","shell.execute_reply.started":"2022-04-15T12:20:21.323511Z","shell.execute_reply":"2022-04-15T12:20:21.338006Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# map the k means labels to the actual labels using reference_labels_dict\npred_labels = map_kmeans_to_actual_labels(model_kmeans_basic.labels_, reference_labels_dict)\n# calc accuracy\naccuracy_score(pred_labels ,truth_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:20:21.340168Z","iopub.execute_input":"2022-04-15T12:20:21.340410Z","iopub.status.idle":"2022-04-15T12:20:21.392774Z","shell.execute_reply.started":"2022-04-15T12:20:21.340367Z","shell.execute_reply":"2022-04-15T12:20:21.392128Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"## KNN\n##### Sources:\nhttps://www.kaggle.com/olaniyan/image-classification-using-knn","metadata":{}},{"cell_type":"code","source":"# initializing k means with 12 clusters (we have 12 classes)\ndef knn(input_labels, input_images):\n    model_knn = OneVsRestClassifier(KNeighborsClassifier())\n    model_knn.fit(input_images,input_labels)\n    return model_knn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Gray scaling + segmentation (with sharpening)","metadata":{}},{"cell_type":"code","source":"# initialize knn and fit on images\nmodel_knn_gray = knn(labels_gray, images_gray)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:25:40.516790Z","iopub.execute_input":"2022-04-15T12:25:40.517317Z","iopub.status.idle":"2022-04-15T12:25:57.531946Z","shell.execute_reply.started":"2022-04-15T12:25:40.517281Z","shell.execute_reply":"2022-04-15T12:25:57.531074Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"predictions = model_knn_gray.predict(images_test_gray)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:29:30.091641Z","iopub.execute_input":"2022-04-15T12:29:30.091937Z","iopub.status.idle":"2022-04-15T12:33:00.912116Z","shell.execute_reply.started":"2022-04-15T12:29:30.091903Z","shell.execute_reply":"2022-04-15T12:33:00.911310Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# save to df\ndf = pd.DataFrame({'file': os.listdir('../input/plant-seedlings-classification/test'), 'species': predictions})\ndf.to_csv('knn_gray_results.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:33:48.923601Z","iopub.execute_input":"2022-04-15T12:33:48.924206Z","iopub.status.idle":"2022-04-15T12:33:48.944784Z","shell.execute_reply.started":"2022-04-15T12:33:48.924169Z","shell.execute_reply":"2022-04-15T12:33:48.943951Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"### 2. Segmentation (with sharpening)","metadata":{}},{"cell_type":"code","source":"# initialize knn and fit on images\nmodel_knn_seg = knn(labels, images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model_knn_seg.predict(images_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save to df\ndf = pd.DataFrame({'file': os.listdir('../input/plant-seedlings-classification/test'), 'species': predictions})\ndf.to_csv('knn_seg_results.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. No pre-processing","metadata":{}},{"cell_type":"code","source":"# initialize knn and fit on images\nmodel_knn_basic = knn(labels_basic, images_basic)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:26:51.158110Z","iopub.execute_input":"2022-04-15T12:26:51.158332Z","iopub.status.idle":"2022-04-15T12:27:41.303799Z","shell.execute_reply.started":"2022-04-15T12:26:51.158306Z","shell.execute_reply":"2022-04-15T12:27:41.303075Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"predictions = model_knn_basic.predict(images_test_basic)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:47:07.597866Z","iopub.execute_input":"2022-04-15T12:47:07.598157Z","iopub.status.idle":"2022-04-15T12:57:42.536193Z","shell.execute_reply.started":"2022-04-15T12:47:07.598114Z","shell.execute_reply":"2022-04-15T12:57:42.535433Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# save to df\ndf = pd.DataFrame({'file': os.listdir('../input/plant-seedlings-classification/test'), 'species': predictions})\ndf.to_csv('knn_basic_results.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:57:42.537611Z","iopub.execute_input":"2022-04-15T12:57:42.537998Z","iopub.status.idle":"2022-04-15T12:57:42.551255Z","shell.execute_reply.started":"2022-04-15T12:57:42.537964Z","shell.execute_reply":"2022-04-15T12:57:42.550510Z"},"trusted":true},"execution_count":62,"outputs":[]}]}